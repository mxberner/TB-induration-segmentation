{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaKOm8eMf5aH",
        "outputId": "45ca9bd4-ef74-4d97-8a2a-c1809d3357b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total usable images: 124\n",
            "Epoch 01/20 | Train Loss: 0.5526, Acc: 0.8081 | Val Loss: 4.4371, Acc: 0.8400\n",
            "Epoch 02/20 | Train Loss: 0.4021, Acc: 0.8485 | Val Loss: 0.4209, Acc: 0.8400\n",
            "Epoch 03/20 | Train Loss: 0.3506, Acc: 0.8384 | Val Loss: 1.5379, Acc: 0.1600\n",
            "Epoch 04/20 | Train Loss: 0.3533, Acc: 0.8485 | Val Loss: 0.4027, Acc: 0.8400\n",
            "Epoch 05/20 | Train Loss: 0.3264, Acc: 0.8485 | Val Loss: 0.6055, Acc: 0.5200\n",
            "Epoch 06/20 | Train Loss: 0.3474, Acc: 0.8283 | Val Loss: 0.3999, Acc: 0.8400\n",
            "Epoch 07/20 | Train Loss: 0.3642, Acc: 0.8485 | Val Loss: 0.4705, Acc: 0.8400\n",
            "Epoch 08/20 | Train Loss: 0.3712, Acc: 0.8485 | Val Loss: 0.4276, Acc: 0.8400\n",
            "Epoch 09/20 | Train Loss: 0.3629, Acc: 0.8485 | Val Loss: 0.4749, Acc: 0.8400\n",
            "Epoch 10/20 | Train Loss: 0.3697, Acc: 0.8384 | Val Loss: 0.3522, Acc: 0.8400\n",
            "Epoch 11/20 | Train Loss: 0.3364, Acc: 0.8485 | Val Loss: 0.3417, Acc: 0.8400\n",
            "Epoch 12/20 | Train Loss: 0.3450, Acc: 0.8485 | Val Loss: 0.4160, Acc: 0.8400\n",
            "Epoch 13/20 | Train Loss: 0.2858, Acc: 0.8788 | Val Loss: 0.8740, Acc: 0.4000\n",
            "Epoch 14/20 | Train Loss: 0.3516, Acc: 0.8384 | Val Loss: 0.5814, Acc: 0.6400\n",
            "Epoch 15/20 | Train Loss: 0.3415, Acc: 0.8485 | Val Loss: 0.4865, Acc: 0.8400\n",
            "Epoch 16/20 | Train Loss: 0.2922, Acc: 0.8586 | Val Loss: 0.5376, Acc: 0.6800\n",
            "Epoch 17/20 | Train Loss: 0.3083, Acc: 0.8384 | Val Loss: 0.3616, Acc: 0.8800\n",
            "Epoch 18/20 | Train Loss: 0.3610, Acc: 0.8586 | Val Loss: 0.3783, Acc: 0.9200\n",
            "Epoch 19/20 | Train Loss: 0.3161, Acc: 0.8485 | Val Loss: 0.4279, Acc: 0.8400\n",
            "Epoch 20/20 | Train Loss: 0.3453, Acc: 0.8687 | Val Loss: 0.6727, Acc: 0.6000\n",
            "\n",
            "Evaluating final model accuracy...\n",
            "\n",
            "Final Model Accuracy: 0.7177\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "import json\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/CV Pictures/RoboFlow COCO JSON')\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Dataset that reads COCO\n",
        "# =========================\n",
        "\n",
        "class COCOTSTDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for Tuberculin Skin Test (TST) based on COCO annotations.\n",
        "\n",
        "    Assumes:\n",
        "        - category_id == 1: induration\n",
        "        - category_id == 2: sticker (calibration marker)\n",
        "        - physical sticker diameter = 6 mm\n",
        "\n",
        "    For each image:\n",
        "        1. Find sticker bbox -> estimate sticker diameter in pixels.\n",
        "        2. Compute mm_per_px = 6.0 / sticker_px.\n",
        "        3. Find induration area/bbox -> estimate diameter in pixels.\n",
        "        4. Convert to mm and assign label:\n",
        "            label = 1 if diameter_mm >= threshold_mm else 0\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        coco_json_path,\n",
        "        image_root,\n",
        "        ind_cat_id=1,\n",
        "        sticker_cat_id=2,\n",
        "        threshold_mm=5.0,\n",
        "        use_area=True,\n",
        "        transform=None,\n",
        "    ):\n",
        "        with open(coco_json_path, \"r\") as f:\n",
        "            coco = json.load(f)\n",
        "\n",
        "        self.image_root = image_root\n",
        "        self.threshold_mm = threshold_mm\n",
        "\n",
        "        images = {img[\"id\"]: img for img in coco[\"images\"]}\n",
        "        annos_by_img = defaultdict(list)\n",
        "        for a in coco[\"annotations\"]:\n",
        "            annos_by_img[a[\"image_id\"]].append(a)\n",
        "\n",
        "        self.samples = []\n",
        "        for img_id, img in images.items():\n",
        "            annos = annos_by_img.get(img_id, [])\n",
        "\n",
        "            sticker = None\n",
        "            induration = None\n",
        "            for a in annos:\n",
        "                if a[\"category_id\"] == sticker_cat_id:\n",
        "                    sticker = a\n",
        "                elif a[\"category_id\"] == ind_cat_id:\n",
        "                    induration = a\n",
        "\n",
        "            # Skip if missing either annotation\n",
        "            if sticker is None or induration is None:\n",
        "                continue\n",
        "\n",
        "            # --- Sticker diameter in pixels (average of bbox w/h) ---\n",
        "            sx, sy, sw, sh = sticker[\"bbox\"]\n",
        "            sticker_px = (sw + sh) / 2.0\n",
        "            if sticker_px <= 0:\n",
        "                continue\n",
        "\n",
        "            mm_per_px = 6.0 / sticker_px  # 6 mm calibration marker\n",
        "\n",
        "            # --- Induration diameter in pixels ---\n",
        "            if use_area and induration.get(\"area\", 0) > 0:\n",
        "                A = float(induration[\"area\"])\n",
        "                ind_px = 2.0 * math.sqrt(A / math.pi)  # equivalent circle\n",
        "            else:\n",
        "                bx, by, bw, bh = induration[\"bbox\"]\n",
        "                ind_px = max(bw, bh)\n",
        "\n",
        "            diameter_mm = ind_px * mm_per_px\n",
        "            label = 1.0 if diameter_mm >= threshold_mm else 0.0\n",
        "\n",
        "            self.samples.append(\n",
        "                {\n",
        "                    \"image_path\": os.path.join(image_root, img[\"file_name\"]),\n",
        "                    \"diameter_mm\": diameter_mm,\n",
        "                    \"label\": label,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if transform is None:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        img = Image.open(s[\"image_path\"]).convert(\"RGB\")\n",
        "        x = self.transform(img)\n",
        "        y = torch.tensor(s[\"label\"], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# =========================\n",
        "# U-Net backbone (encoder) + classifier head\n",
        "# =========================\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(Conv2d -> BN -> ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class UNetClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net encoder used as a feature extractor + global pooling + FC for\n",
        "    binary classification (TB present if induration >= 5mm).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels=3):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)      # 64\n",
        "        x2 = self.down1(x1)   # 128\n",
        "        x3 = self.down2(x2)   # 256\n",
        "        x4 = self.down3(x3)   # 512\n",
        "        x5 = self.down4(x4)   # 1024 (bottleneck)\n",
        "\n",
        "        pooled = self.global_pool(x5)      # [B, 1024, 1, 1]\n",
        "        pooled = pooled.view(pooled.size(0), -1)  # [B, 1024]\n",
        "        logits = self.fc(pooled)           # [B, 1]\n",
        "        return logits.squeeze(1)           # [B]\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Training / evaluation\n",
        "# =========================\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def eval_one_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "\n",
        "    COCO_JSON = \"train/_annotations.coco.json\"  # path to your COCO file\n",
        "    IMAGE_ROOT = \"train\"                 # folder containing the image files\n",
        "\n",
        "    batch_size = 8\n",
        "    num_epochs = 20\n",
        "    lr = 1e-3\n",
        "    val_split = 0.2     # 80/20 split\n",
        "    threshold_mm = 5.0  # TB positive if diameter >= 5mm\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    dataset = COCOTSTDataset(\n",
        "        coco_json_path=COCO_JSON,\n",
        "        image_root=IMAGE_ROOT,\n",
        "        threshold_mm=threshold_mm,\n",
        "        use_area=True,\n",
        "    )\n",
        "\n",
        "    print(f\"Total usable images: {len(dataset)}\")\n",
        "\n",
        "    # Extract labels for stratified split\n",
        "    labels = [s[\"label\"] for s in dataset.samples]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        indices,\n",
        "        test_size=val_split,\n",
        "        random_state=42,\n",
        "        stratify=labels\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                            shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = UNetClassifier(n_channels=3).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, optimizer, criterion, device\n",
        "        )\n",
        "        val_loss, val_acc = eval_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d}/{num_epochs} | \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "    # =========================\n",
        "    # Final Accuracy (CIFAR-style)\n",
        "    # =========================\n",
        "\n",
        "    print(\"\\nEvaluating final model accuracy...\")\n",
        "\n",
        "    test_loader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(inputs)\n",
        "\n",
        "        # Convert logits → probabilities → predicted class (0 or 1)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        predicted = (probs >= 0.5).float()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"\\nFinal Model Accuracy: {correct / total:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}